{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Background\n",
    "In 2017, I worked on a consulting project for a marijuana company in Denver, Colorado. There was a sense in the community at that time that Colorado was paving the way for legalization and the industry was much more inclusive and wealth distributed than other commercial sectors. That communal notion has little validity looking at the current economic landscape where over 80% of business owners are white, in contrast to a historical record of disproportionately targeting Black and Latinx people for marijuana possession. (A study from Queens College found that before legalization Black and Latinx people were 13 percentage points more disproportinately targeted for marijuana possession arrests than White counterparts). Everywhere, the argument seemed to be \"ok, we're working on being more socially equitable from a minority-inclusive perspective but we're doing a great job from an income class perspective.\" This led me to wonder: Who owns Marijuana in Colorado, actually? How distributed is income amongst people? In an attempt to answer this question, I thought that looking at retail license owners would be a good starting proxy for market share and ownership. To access all retail licenses, I scraped Colorado's Revenue Department's website.\n",
    "\n",
    "Update: Marijuana co-ops were recently banned in Colorado and there's a current bill on the docket to expunge the records of all those with posession records. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T19:44:12.877713Z",
     "start_time": "2020-02-24T19:44:12.346641Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T19:44:14.610746Z",
     "start_time": "2020-02-24T19:44:14.599757Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#the goal is to make a list of dictionaries of licensees that we can turn into a dataframe\n",
    "licensees=[]\n",
    "#for debugging purposes:\n",
    "# failed =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T19:44:47.798100Z",
     "start_time": "2020-02-24T19:44:20.622108Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#for debugging: chromedriver must be compatible with current version of chrome\n",
    "driver=webdriver.Chrome('./chromedriver')\n",
    "driver.get('https://codor.mylicense.com/med_verification/Search.aspx?facility=N')\n",
    "\n",
    "button=Select(driver.find_element_by_css_selector('#t_web_lookup__license_type_name'))\n",
    "options = button.options\n",
    "\n",
    "#There are 8 different license types to iterate through. \n",
    "#When you select a license type and click \"search,\" all last names of that license type will show up\n",
    "#If you select \"All\" for license type, you would have to specify a letter of the alphabet\n",
    "#For this reason, it's generally more efficient to iterate through license types (the index of the license type on the main menu bar will be num)\n",
    "# use range (1,9) to collect all\n",
    "#for demo, comment out the whole range and just comment in the lower range (6,7)\n",
    "for num in range(1,9):\n",
    "# for num in range(6,7):\n",
    "    driver.get('https://codor.mylicense.com/med_verification/Search.aspx?facility=N')\n",
    "    button=Select(driver.find_element_by_css_selector('#t_web_lookup__license_type_name'))\n",
    "    #num is the index of the license type in the menu bar (we want to skip \"all\" so we start with 1)\n",
    "    button.select_by_index(num)\n",
    "    text_input = driver.find_element_by_css_selector('#t_web_lookup__last_name')\n",
    "    # Every time there's a search, there are unique urls generated, there are so many pages for \"Key\" (num 6) that the urls we collect timeout before we can grab info from them\n",
    "    #For this reason,I had to add letter batching for the \"key option ;comment out for demo purposes\n",
    "    if num == 6:\n",
    "        for letter in ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']:\n",
    "            text_input.send_keys(letter)\n",
    "            search = driver.find_element_by_css_selector('#sch_button')\n",
    "            search.click()\n",
    "        #collect individual person data\n",
    "        #while True is because we paginate with a css_selector element and break when there are no more next page elements\n",
    "        #the reason we did not paginate with number elements is that we are only displayed 40 pages at a time and a \"...\" item you click to see more\n",
    "        #if this were to be run more than one time, it would probably be more readable to turn this section into a function, as it is used for all cases\n",
    "            while True:\n",
    "                #in this case, we selected all elements that contained a link to an individual person's license \n",
    "                for a in driver.find_elements_by_css_selector(\"td[rowspan='0'] a\"):\n",
    "                        #extract the link element\n",
    "                        try:\n",
    "                            link = a.get_attribute('href')\n",
    "                        #if there exists an element that should have a link but we fail to extract it, we should append to a failed list for troubleshooting\n",
    "                        except:\n",
    "                            failed.append(a)\n",
    "                            continue\n",
    "                        a.click()\n",
    "                        #after clicking on a each person, you need to switch windows to grab the info for the next person\n",
    "                        driver.switch_to.window(driver.window_handles[1])\n",
    "                        #once we click the link for the person, we can switch to BeautifulSoup for a cleaner scraping experience\n",
    "                        html = driver.page_source\n",
    "                        soup = BeautifulSoup(html)\n",
    "                        person ={}\n",
    "                        full_name = soup.find('span', id=\"_ctl25__ctl1_full_name\")\n",
    "                        try:\n",
    "                            person['full_name']=full_name.text\n",
    "                        #sometimes an individual page is slow to load and thus full_name doesn't exist yet, if there's a failure, we should sleep and try again\n",
    "                        #we'll try twice with time.sleep(2) first to save time and time.sleep(5) to ensure that it really isn't just a page load issue\n",
    "                        except:\n",
    "                            time.sleep(2)\n",
    "                        try:\n",
    "                            person['full_name']=full_name.text\n",
    "\n",
    "                        except:\n",
    "                            time.sleep(5)\n",
    "                        try:\n",
    "                            person['plicense']=soup.find(id='_ctl32__ctl1_license_no').text\n",
    "                        #if it still fails, we'll append the link to the list of failed items\n",
    "                        #ideally, this list could be used for a test where an empty list is success\n",
    "                        except:\n",
    "                            failed.append(link)\n",
    "                            continue    \n",
    "                        person['plicense']=soup.find(id='_ctl32__ctl1_license_no').text\n",
    "                        print(full_name.text)\n",
    "                        #finding the facility license\n",
    "                        regexp = re.compile(r'_ctl37__ct.*_license_no')\n",
    "                        licenses = soup.find_all(id=regexp)\n",
    "                        #some people have multiple licenses to their name, let's grab all of them\n",
    "                        for license in licenses:\n",
    "                            print(license.text)\n",
    "                            person['flicense'] = license.text\n",
    "                            licensees.append(person)\n",
    "                        print('------------')\n",
    "                        #after a certain number of windows are open, selenium will crash so it is good practice to close the window\n",
    "                        driver.close()\n",
    "                        #switch back to the main search result page to paginate or move on\n",
    "                        driver.switch_to.window(driver.window_handles[0])\n",
    "            #once we have iterated through all the names/links on the page, we must go to the next page (unless it's the last)\n",
    "            #if there is a next page, we'll click it to start the loop again\n",
    "                try:\n",
    "                    nextPage = driver.find_element_by_css_selector('#datagrid_results > tbody > tr:last-child span + a')\n",
    "                    nextPage.click()\n",
    "                except:\n",
    "                    break\n",
    "                #Have to go through the flow again and search for the next letter\n",
    "                driver.get('https://codor.mylicense.com/med_verification/Search.aspx?facility=N')\n",
    "                button=Select(driver.find_element_by_css_selector('#t_web_lookup__license_type_name'))\n",
    "                #here, we know that we only want to select the 6th (Key) license type\n",
    "                button.select_by_index(6)\n",
    "                text_input = driver.find_element_by_css_selector('#t_web_lookup__last_name')\n",
    "                    \n",
    "                            \n",
    "    else:\n",
    "        search = driver.find_element_by_css_selector('#sch_button')\n",
    "        search.click()\n",
    "\n",
    "    while True:\n",
    "# this is for each individual person\n",
    "#see note above for additional comments\n",
    "        for a in driver.find_elements_by_css_selector(\"td[rowspan='0'] a\"):\n",
    "            try:\n",
    "                link = a.get_attribute('href')\n",
    "            except:\n",
    "                failed.append(a)\n",
    "                continue\n",
    "            a.click()\n",
    "            #after clicking on a each person, you need to switch windows to grab the info for the next person\n",
    "            driver.switch_to.window(driver.window_handles[1])\n",
    "            #once we click the link for the person, we can switch to BeautifulSoup for a cleaner scraping experience\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html)\n",
    "            person ={}\n",
    "            full_name = soup.find('span', id=\"_ctl25__ctl1_full_name\")\n",
    "            try:\n",
    "                person['full_name']=full_name.text\n",
    "            except:\n",
    "                time.sleep(2)\n",
    "            try:\n",
    "                person['full_name']=full_name.text\n",
    "\n",
    "            except:\n",
    "                time.sleep(5)\n",
    "            try:\n",
    "                person['plicense']=soup.find(id='_ctl32__ctl1_license_no').text\n",
    "            except:\n",
    "                failed.append(link)\n",
    "                continue    \n",
    "            person['plicense']=soup.find(id='_ctl32__ctl1_license_no').text\n",
    "            print(full_name.text)\n",
    "            #finding the facility license\n",
    "            regexp = re.compile(r'_ctl37__ct.*_license_no')\n",
    "            licenses = soup.find_all(id=regexp)\n",
    "            for license in licenses:\n",
    "                print(license.text)\n",
    "                person['flicense'] = license.text\n",
    "                licensees.append(person)\n",
    "            print('------------')\n",
    "            driver.close()\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "        #once we have iterated through all the names/links on the page, we must go to the next page (unless it's the last)\n",
    "        try:\n",
    "            nextPage = driver.find_element_by_css_selector('#datagrid_results > tbody > tr:last-child span + a')\n",
    "            nextPage.click()\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    # when there's no more next page, we'll want to return back to the search page and go to the next index number\n",
    "    driver.get('https://codor.mylicense.com/med_verification/Search.aspx?facility=N')\n",
    "    button=Select(driver.find_element_by_css_selector('#t_web_lookup__license_type_name'))\n",
    "    button.select_by_index(num)\n",
    "    text_input = driver.find_element_by_css_selector('#t_web_lookup__last_name')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(licensees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('colorado_licenses.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
