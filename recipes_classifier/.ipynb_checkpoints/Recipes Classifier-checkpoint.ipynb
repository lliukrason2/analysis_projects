{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing text analysis on recipe ingredients + cuisines\n",
    "\n",
    "**Topics:** Text analysis, classifiers\n",
    "\n",
    "**Datasets**\n",
    "\n",
    "- **recipes.csv** Once upon a time I scraped a bunch of recipes, not sure where they're from.\n",
    "\n",
    "## Imports\n",
    "\n",
    "We're going to be using\n",
    "\n",
    "* Pandas\n",
    "* Regular expressions\n",
    "* Decision Trees\n",
    "* Random Forests\n",
    "* Logistic Regression\n",
    "* Confusion matrices\n",
    "* CountVectorizer\n",
    "* TfidfVectorizer\n",
    "\n",
    "Import everything you need for those. It's easier than doing them one-by-one later, I think! We're also going to be doing the graphviz tree visualization, but I always just cut and paste that entire block as a unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in our data\n",
    "\n",
    "There's nothing too complicated about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('recipes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing the ingredient list\n",
    "\n",
    "These words aren't going to do us much good unless we can convert them to text. Use the `CountVectorizer` to count the number of times each word appears in each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_on_commas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-69484d8b1662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcount_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit_on_commas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'split_on_commas' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your result should be a dataframe named `words_df` that looks like a much wider version of this:\n",
    "    \n",
    "|00|10|...|zucchini|Ã©pices|\n",
    "|---|---|---|---|---|\n",
    "|0|0|...|0|0|\n",
    "|0|0|...|0|0|\n",
    "|0|0|...|0|0|\n",
    "|0|0|...|0|0|\n",
    "|0|0|...|0|0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting\n",
    "\n",
    "### Count up how many times each word is used\n",
    "\n",
    "Don't think too hard about this, there's nothing fancy about how you do this.\n",
    "\n",
    "* **Tip:** Just imagine it's a normal dataframe and you want to add up each column.\n",
    "* **Tip:** ...or imagine you're trying to add up _one_ column but you forget the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the top 10 most common ingredients?\n",
    "\n",
    "You'll want to use the results from the last question. Again, don't overthink it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does anything seem wrong with those ingredients?\n",
    "\n",
    "Do they all seem very ingredient-y to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at your original recipes dataframe again\n",
    "\n",
    "What do the ingredients look like? How would you as a _person_ separate them compared to how the vectorizer did it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a custom tokenizer\n",
    "\n",
    "Usually we can trust what the vectorizer does to the words, but this time we can't! Since we have a better idea about how to split it, we use a custom function to split each piece of text up.\n",
    "\n",
    "To do this: copy and paste your code where you counted words up above. Add `tokenizer=split_on_commas` to `CountVectorizer` to tell it to use my custom function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_on_commas(text):\n",
    "    # Split the list on commas, then remove any extra whitespace\n",
    "    pieces = text.split(\",\")\n",
    "    no_spaces = [piece.strip() for piece in pieces if piece]\n",
    "    return no_spaces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't that look nicer??\n",
    "\n",
    "_Yes!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word counting, again\n",
    "\n",
    "Get the top 15 most common ingredients. **It should be a much nicer list!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using our cuisines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the most popular cuisines?\n",
    "\n",
    "* **Tip:** You'll need to go back to your original dataframe for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find every recipe that uses soy sauce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's are the top 5 cuisines that uses soy sauce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, soy sauce seems pretty common in Chinese food. **Maybe we could do something with that?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Chinese food detector\n",
    "\n",
    "Create a new column in your original dataframe called `is_chinese`. It should be `1` if the recipe is Chinese, `0` if the recipe is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that you have 2,673 Chinese recipes and 37,101 non-Chinese recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building your features\n",
    "\n",
    "To use a classifier, we need to build an `X` and a `y`.\n",
    "\n",
    "* Your `X` is going to be the word counts for each recipe\n",
    "* Your `y` is going to be whether each recipe Chinese or not\n",
    "\n",
    "This is going to be a little different than what we normally do. Typically we use `.drop(column=` to remove our label, but this time we have **two separate dataframes** we're managing, so don't be surprised if you don't sue it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that `X` is a dataframe of numbers (mostly zeroes) and `y` is a single column of `0`s and `1`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into test and train datasets\n",
    "\n",
    "If we train our classifier on all of our recipes, it might cheat and memorize the answers (aka overfitting). Instead, we'll need to use `train_test_split` to separate into a training set it can study, and a test set we can use to see how well it performs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using our classifiers\n",
    "\n",
    "## Decision Tree\n",
    "\n",
    "**Create a decision tree classifier, and train it on our training data.** You can make a decision tree classifier like this:\n",
    "\n",
    "```python\n",
    "clf = DecisionTreeClassifier()\n",
    "```\n",
    "\n",
    "You'll want to also give it `max_depth=5` so we can visualize it without too much trouble later - otherwise it'll make many many decisions which will make a large complicated graphic.\n",
    "\n",
    "Additionally, put `%%time` in the first row of the cell to see how long it takes to train our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out our confusion matrix \n",
    "\n",
    "Use the one from our notes and homework, not the default scikit-learn version. The output should look something like this:\n",
    "\n",
    "|.|Predicted not chinese|Predicted chinese|\n",
    "|---|---|---|\n",
    "|Is not chinese|9209|60|\n",
    "|Is chinese|377|298|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do we feel about our classifier's performance?** Describe what is happening in the \"is chinese\" row using words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the important features?\n",
    "\n",
    "You can use the following code to see feature importance for a decision tree.\n",
    "\n",
    "```python\n",
    "feature_names = X.columns\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'feature importance': importances,\n",
    "}).sort_values(by='feature importance', ascending=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gave it a lot of columns to pay attention to, so **why are so many of them zero?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the decision tree\n",
    "\n",
    "While those numbers are fun (if a little long), the _real fun_ is visualizing the tree itself. You can use this code to do that:\n",
    "\n",
    "```python\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "label_names = ['not chinese', 'chinese']\n",
    "feature_names = X.columns\n",
    "\n",
    "dot_data = tree.export_graphviz(clf,\n",
    "                    feature_names=feature_names,  \n",
    "                    filled=True,\n",
    "                    class_names=label_names)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you think about that?** If you know about cooking or ingredients, do you recognize what some of those splits mean in terms of different cuisines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "A random forest is like making a bunch of decision trees work together. **Create a random forest classifier, and train it on our data.**\n",
    "\n",
    "```python\n",
    "clf = RandomForestClassifier()\n",
    "```\n",
    "\n",
    "Right now, the `RandomForestClassifier` uses 10 decision trees to make its decision, with `n_estimators=10` being the default. You'll see a warning about how it's going to change to `100` in a future version.\n",
    "\n",
    "You can try to use `100` now, but notice how long it takes! Use `%%time` to time how long it takes to train the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the feature importances?\n",
    "\n",
    "You can re-use your decision tree code. Are the results any different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why can't we draw a tree for a random forest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying with a logistic regression\n",
    "\n",
    "To be a real data scientist, you throw every kind of classifier at your project until you find the one that works the best. Is that science? I don't know, really, but it's definitely reality.\n",
    "\n",
    "## Building our classifier\n",
    "\n",
    "This is the standard way to build a logistic regression classifier:\n",
    "\n",
    "```python\n",
    "clf = LogisticRegression(C=1e9, solver='lbfgs')\n",
    "```\n",
    "\n",
    "> You might get an error when fitting, though, that says \"Increase the number of iterations.\" This means the regression failed to find a good answer, and you need to tell it to work harder. To do that, you need to set `max_iter=` to a higher number.\n",
    ">\n",
    "> The default is 100, and in previous homeworks we've cranked it up to 4000 with no problem. This time it isn't so easy - we have a lot lot lot lot of features this time, though, and every iteration makes the regression take more time until we get very very bored of things.\n",
    ">\n",
    "> You can solve this three ways:\n",
    ">\n",
    "> * Scroll up and add a `max_features=` to your vectorizer so it only picks a certain (lower) number of features, then re-run\n",
    "> * Be very patient\n",
    "> * Train on less data, by doing for example `clf.fit(X_train.head(7000), y_train.head(7000))`\n",
    "> \n",
    "> I used `%%time` to see how long .fit would take with `max_iter=1000` - it ran for 5 minutes before it finished, but it never converged (aka got an answer)! My computer's old, but if you try that route you should go get a snack.\n",
    "\n",
    "**Build a logistic classifier and train it on our training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the coefficients\n",
    "\n",
    "Use this code to print out the coefficients, it's slightly different than the decision tree version:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "feature_names = X.columns\n",
    "coefficients = clf.coef_[0]\n",
    "\n",
    "pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient (log odds ratio)': coefficients,\n",
    "    'odds ratio': np.exp(coefficients).round(4)\n",
    "}).sort_values(by='odds ratio', ascending=False)\n",
    "```\n",
    "\n",
    "I might throw a `.head(20)` on there so you only see the top ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are pretty different from our decision tree.\n",
    "\n",
    "**Why might these numbers be so different compared to our decision tree?** Think about how decision trees and logistic regression work. Or maybe go answer the next question and then come back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use words to describe what the odds ratio for your top ingredient means.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the confusion matrix\n",
    "\n",
    "How well does it do compared to the previous two classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe in words how well it does at accurately predicting Chinese food recipes as being Chinese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which was your best classifier so far?\n",
    "\n",
    "Do you have to think about what \"best\" means, or is these a clear winner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upgrading to a TF-IDF Vectorizer\n",
    "\n",
    "Vectorizing using TF-IDF is almost always better than using simple counts. You can't find the most popular words or anything, but common words get downgraded and less common, more descriptive words end up rising in importance. And that seems cool!\n",
    "\n",
    "Take your `CountVectorizer` code from up above and change it to use a `TfidfVectorizer`. I'll leave the `split_on_commas` code here as a start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_on_commas(text):\n",
    "    pieces = text.split(\",\")\n",
    "    no_spaces = [piece.strip() for piece in pieces if piece]\n",
    "    return no_spaces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our features\n",
    "\n",
    "Create our `X` and `y` variables. Our `X` should be the adjusted word frequencies, and `y` should be whether the recipe is Chinese or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once that's done, be sure to split your features and labels into test and train datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees\n",
    "\n",
    "**Create a decision tree and train it on our data.** Time how long it takes to complete training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does it use to make its decisions?\n",
    "\n",
    "You can either show me feature importances or the actual tree that's built (if you're using a low enough `max_features`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this with what you got with the CountVectorizer. Do they seem that different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How well does this classifier do?\n",
    "\n",
    "Confusion matrix, please."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it perform better than the `CountVectorizer` version?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression classifier\n",
    "\n",
    "I don't think we did that much better - if any better - with our new version. Let's try one more time using logistic regression.\n",
    "\n",
    "If you get the \"could not converge, increase iterations\" error, refer to the tips up above about `max_iter` and `max_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: What is \"vectorization?\" Why do we do it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: What's the general difference between a `CountVectorizer` and a `TfidfVectorizer`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Why did we end up using a custom tokenizer instead of the default scikit-learn one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: What's the best combination of vectorizer + classifier we've used? Does \"best\" depend on what's important to us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: How do you feel about trying out random classifiers until you find the \"best\" one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: What's the most \"Chinese\" ingredient? You might have a different answer based on what type of classifier you're using - why is that?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: If you look at the top few words for the random forest, most of them are various types of soy sauce. How could you improve upon that when if you were spending more time with this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: Scikit-learn vectorizers have a lot of options. Among those are `max_features`, which only takes the top n features, and `min_df`/`max_df`, which only allows words that show up above or below a certain percentage of the documents. For example, `max_df` of 0.75 removes any words that show up in more than 75% of documents. When might these options be useful?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9: If you had to explain a classifier to someone, would you rather explain a logistic regression or a decision tree? Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10: A random forest performs better than a decision tree, but it's easy to see how a decision tree works by looking at the flow chart. If you had to explain to your readers the algorithm behind your analysis, would you choose a better-performing algorithm or one that is easier to explain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus!!!\n",
    "\n",
    "## Multi-class problems\n",
    "\n",
    "Did you know that `DecisionTreeClassifier` can actually support multiple classes, not just two? Probably not, since I've kept it a secret. If you're interested, let's try this out.\n",
    "\n",
    "### Convert categories to numbers\n",
    "\n",
    "First, convert the `cuisine` column into a category with `.astype('category')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cuisine looks like a string, but it's now secretly a number. You can use `.cat.codes` to get the code out. Assign that to a new column called `cuisine_code`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a new `X` and `y`**. The `X` is the vectorized words, and the `y` is the cuisine code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test train split!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a decision tree** and train it on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix code is a little different, but here you go:\n",
    "\n",
    "```python\n",
    "y_true = y_test\n",
    "y_pred = clf.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(df.cuisine.cat.categories)\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
