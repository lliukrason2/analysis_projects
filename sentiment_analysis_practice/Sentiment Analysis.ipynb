{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Lots of libraries exist that will do sentiment analysis for you. Imagine that: just taking a sentence, throwing it into a library, and geting back a score! How convenient!\n",
    "\n",
    "It's also **totally irresponsible** unless you know how the sentiment analyzer was built. In this homework we're going to see how sentiment analysis is done with a few packages.\n",
    "\n",
    "## Installation\n",
    "\n",
    "If you haven't already, you'll want to `pip install` two packages: NLTK and Textblob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk\n",
    "# !pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK: Natural Language Tooklit\n",
    "\n",
    "[Natural Language Toolkit](https://www.nltk.org/) is the basis for a lot of text analysis done in Python. It's old and terrible and slow, but it's just been used for so long and does so many things that it's generally the default when people get into text analysis. The new kid on the block is [spaCy](https://spacy.io/) (but it doesn't do sentiment analysis so we're leaving it out of this).\n",
    "\n",
    "When you first run NLTK, you need to download some datasets to make sure it will be able to do everything you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/minami/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/minami/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/minami/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do sentiment analysis with NLTK, it only takes a couple lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.153, 'neu': 0.688, 'pos': 0.159, 'compound': 0.0276}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "sia = SIA()\n",
    "sia.polarity_scores(\"This restaurant was great, but I'm not sure if I'll go there again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asking `SentimentIntensityAnalyzer` for the `polarity_score` gave us four values in a dictionary:\n",
    "\n",
    "- **negative:** the negative sentiment in a sentence\n",
    "- **neutral:** the neutral sentiment in a sentence\n",
    "- **positive:** the postivie sentiment in the sentence\n",
    "- **compound:** the aggregated sentiment. \n",
    "    \n",
    "Seems simple enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I just got a call from my boss - does he realise it's Saturday?\"\n",
    "sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in real life, if you use an emoji you can be read as being more positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.786, 'pos': 0.214, 'compound': 0.4588}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I just got a call from my boss - does he realise it's Saturday? :)\"\n",
    "sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I just got a call from my boss - does he realise it's Saturday? ðŸ˜Š\"\n",
    "sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why didn't it understand the emoji the same way it understood the emoticon? Well, **it only knows the words that it's been trained on,** and if VADER's never seen ðŸ˜Š before it won't know what to think of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextBlob\n",
    "\n",
    "TextBlob is built on top of NLTK, but is infinitely easier to use. It's still slow, but _it's so so so easy to use_. \n",
    "\n",
    "You can just feed TextBlob your sentence, then ask for a `.sentiment`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.275, subjectivity=0.8194444444444444)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"This restaurant was great, but I'm not sure if I'll go there again.\")\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How could it possibly be easier than that?!?!?** This time we get a `polarity` and a `subjectivity` instead of all of those different scores, but it's basically the same idea.\n",
    "\n",
    "If you like options: it turns out TextBlob actually has multiple sentiment analysis tools! How fun! We can plug in a different analyzer to get a different result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=0.5879425317005774, p_neg=0.41205746829942275)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"This restaurant was great, but I'm not sure if I'll go there again.\", analyzer=NaiveBayesAnalyzer())\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's a **very different result.** To understand why it's so different, we need to talk about where these sentiment numbers come from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But where do those numbers come from?\n",
    "\n",
    "The most important thing to understand is **sentiment is always just an opinion.** In this case it's an opinion, yes, but specifically **the opinion of a machine.**\n",
    "\n",
    "## VADER\n",
    "\n",
    "NLTK's Sentiment Intensity Analyzer works is using something called **VADER**, which is a list of words that have a sentiment associated with each of them.\n",
    "\n",
    "|Word|Sentiment rating|\n",
    "|---|---|\n",
    "|tragedy|-3.4|\n",
    "|rejoiced|2.0|\n",
    "|disaster|-3.1|\n",
    "|great|3.1|\n",
    "\n",
    "If you have more positives, the sentence is more positive. If you have more negatives, it's more negative. It can also take into account things like capitalization - you can read more about the classifier [here](http://t-redactyl.io/blog/2017/04/using-vader-to-handle-sentiment-analysis-with-social-media-text.html), or the actual paper it came out of [here](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf).\n",
    "\n",
    "**How do they know what's positive/negative?** They came up with a very big list of words, then asked people on the internet and paid them one cent for each word they scored.\n",
    "\n",
    "## TextBlob's `.sentiment`\n",
    "\n",
    "TextBlob's sentiment analysis is based on a separate library called [pattern](https://www.clips.uantwerpen.be/pattern).\n",
    "\n",
    "> The sentiment analysis lexicon bundled in Pattern focuses on adjectives. It contains adjectives that occur frequently in customer reviews, hand-tagged with values for polarity and subjectivity.\n",
    "\n",
    "Same kind of thing as NLTK's VADER, but it specifically looks at words from customer reviews.\n",
    "\n",
    "**How do they know what's positive/negative?** They look at (mostly) adjectives that occur in customer reviews and hand-tag them.\n",
    "\n",
    "## TextBlob's `.sentiment` + NaiveBayesAnalyzer\n",
    "\n",
    "TextBlob's other option uses a `NaiveBayesAnalyzer`, which is a machine learning technique. When you use this option with TextBlob, the sentiment is coming from \"an NLTK classifier trained on a movie reviews corpus.\"\n",
    "\n",
    "**How do they know what's positive/negative?** Looked at movie reviews and scores using machine learning, see what words are associated with a positive/negative rating.\n",
    "\n",
    "## What's this mean for me?\n",
    "\n",
    "When you're doing automatic sentiment analysis, you have two major questions: \n",
    "\n",
    "* Where does the list of known words come from\n",
    "* Where do the positive/negative scores come from\n",
    "\n",
    "Let's compare the tools we've used so far.\n",
    "\n",
    "|technique|word source|word selection|scores|\n",
    "|---|---|---|---|\n",
    "|NLTK (VADER)|everywhere|hand-picked|internet people, word-by-word|\n",
    "|TextBlob|product reviews|hand-picked, mostly adjectives|internet people, word-by-word|\n",
    "|TextBlob + NaiveBayesAnalyzer|movie reviews|all words|automatic based on score|\n",
    "\n",
    "A major thing that should jump out at you is **how different the sources are.**\n",
    "\n",
    "While VADER focuses on content found everywhere, TextBlob's two options are specific to certain domains. The [original paper for VADER](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf) passive-aggressively noted that VADER is effective at general use, but being trained on a specific domain can have benefits: \n",
    "\n",
    "> While some algorithms performed decently on test data from the specific domain for which it was expressly trained, they do not significantly outstrip the simple model we use.\n",
    "\n",
    "They're basically saying, \"if you train a model on words from a certain field, it will be good at that field.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "### Question 1: Is it okay to use a sentiment analyzer built on product reviews to check the sentiment of tweets? How about to check the sentiment of wine reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I would ot feel comfortable using an analyser built on product reviews to analyse tweets. They are too different - \n",
    "especially since tweets tend to be more potentially hateful and harmful than reviews.\n",
    "I would be more ok using it on wine reviews ethically, though wine reivews might use too many\n",
    "wine-specific words like minerals and chalky etc for the model to be of any use.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Is it okay to use a sentiment analyzer trained on everything to check the sentiment of tweets? How about to check the sentiment of wine reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I don't know. I think it's better to use an analyser trained on everything to check tweets and wine reviews\n",
    "than using an analyser trained on product reviews. That said, I think sentiment analysers are too inaccurate\n",
    "to use on their own on something as complicated as tweets.\n",
    "Words have such different meanings depending on context.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: If I'm trying to report on whether people generally like or dislike what is happening throughout the Democratic debates, could I use these sorts of tools on tweets? Let's hear arguments for both sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "YES: It's a useful first step in reporting this topic. There are so many tweets out there that you can't\n",
    "possibly hand-analyse all of them quickly. If it's breaking news and you're under a deadline,\n",
    "using this tool to get a general sense of what the tweets are like is fair game, as long as you make it clear\n",
    "what your methods are and be honest about the limitations of the analyser. It's probably marginally \n",
    "better than reporters handpicking tweets that support their arguments.\n",
    "\n",
    "NO: The sentiment analysis can provide a lede for actual reporting, but you shouldn't rely on it entirely,\n",
    "or trust it, even. Buzz words like \"sentiment analysis\" or \"machine learning\" lend a veneer of objectivity\n",
    "and accuracy, and most readers would get the false impression that the model is much more refined and \n",
    "trustworthy than it actually is. Using sentiment analysis alone to analyse tweets would be misleading and more \n",
    "harmful than beneficial. Also, you give up too much control by letting other people decide what different words mean.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training our own sentiment analyzer\n",
    "\n",
    "We don't want to rely on other people, we want to do this ourselves! There are two major ways to do sentiment analysis:\n",
    "\n",
    "* Have a list of words that you humans assign positive or negative scores to\n",
    "* Look at something scored (movie reviews, product reviews) and figure out which words appear with which scores\n",
    "\n",
    "Depending on how you look at it, it's either a classification or a regression problem. We'll see the difference down below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on tweets\n",
    "\n",
    "Let's say we were going to analyze the sentiment of tweets. If we had a list of tweets that were scored positive vs. negative, we could see which words are usually associated with positive scores and which are usually associated with negative scores.\n",
    "\n",
    "Luckily, we have **Sentiment140** - http://help.sentiment140.com/for-students - a list of 1.6 million tweets along with a score as to whether they're negative (0) or positive (4). We'll use it to build our own machine learning algorithm to see separate positivity from negativity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity          id                      datetime     query  \\\n",
       "0         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4         0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "          username                                            content  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = ['polarity', 'id', 'datetime', 'query', 'username', 'content']\n",
    "df = pd.read_csv(\"trainingandtestdata/training.1600000.processed.noemoticon.csv\", \n",
    "                 names=columns,\n",
    "                 encoding='latin-1')\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning our data\n",
    "\n",
    "The `polarity` field is whether something is positive or negative. How many do we have of each?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the documentation, `0` is negative and `4` is positive. Weird, right? Let's make it zero and one instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polarity'] = df.polarity.replace(4,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm you have 800k of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    800000\n",
       "0    800000\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a **lot of tweets.**\n",
    "\n",
    "Let's be honest: it's going to take our algorithms a long long time to process that many. Instead of working with our entire dataframe, let's use a **sample of 20,000**. If things are still slow before we can decrease this number.\n",
    "\n",
    "* **Tip:** `df.sample(5)` will give you a sample of 5 elements of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.sample(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm you have 20,000 rows and 6 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize our tweets\n",
    "\n",
    "Create a `TfidfVectorizer` and use it to vectorize our tweets. Since we don't have all the time in the world, we should probably use `max_features` to only take a selection of terms - how about 2000 for now?\n",
    "\n",
    "* **Tip:** Your end result should be a `words_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>140</th>\n",
       "      <th>15</th>\n",
       "      <th>17</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yu</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000   09   10  100   11   12  140   15   17  ...  youre  yours  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "\n",
       "   yourself  youtube   yr   yu  yum  yummy  yup  zoo  \n",
       "0       0.0      0.0  0.0  0.0  0.0    0.0  0.0  0.0  \n",
       "1       0.0      0.0  0.0  0.0  0.0    0.0  0.0  0.0  \n",
       "2       0.0      0.0  0.0  0.0  0.0    0.0  0.0  0.0  \n",
       "3       0.0      0.0  0.0  0.0  0.0    0.0  0.0  0.0  \n",
       "4       0.0      0.0  0.0  0.0  0.0    0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=2000)\n",
    "vectors = vectorizer.fit_transform(sample.content)\n",
    "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
    "words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your dataframe should look something like\n",
    "\n",
    "|00|000|10|...|your|...|yummy|yup|Â½t|\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "|0.0|0.0|0.0|...|0.0|...|0.0|0.0|0.0|\n",
    "|0.0|0.0|0.0|...|0.0|...|0.0|0.0|0.0|\n",
    "|0.0|0.0|0.0|...|0.235754|...|0.0|0.0|0.0|\n",
    "|0.0|0.0|0.0|...|0.0|...|0.0|0.0|0.0|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>140</th>\n",
       "      <th>15</th>\n",
       "      <th>17</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yu</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000   09   10  100   11   12  140   15   17  ...  youre  yours  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "\n",
       "   yourself  youtube   yr   yu  yum  yummy  yup  zoo  \n",
       "0       0.0      0.0  0.0  0.0  0.0    0.0  0.0  0.0  \n",
       "\n",
       "[1 rows x 2000 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our algorithm\n",
    "\n",
    "### Setting up our variables\n",
    "\n",
    "Create an `X` and a `y`, same as ever. In this case, what are our **features** and what are our **labels?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>140</th>\n",
       "      <th>15</th>\n",
       "      <th>17</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yu</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000   09   10  100   11   12  140   15   17  ...  youre  yours  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "\n",
       "   yourself  youtube   yr   yu  yum  yummy  yup  zoo  \n",
       "0       0.0      0.0  0.0  0.0  0.0    0.0  0.0  0.0  \n",
       "\n",
       "[1 rows x 2000 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\",2000)\n",
    "words_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333551</th>\n",
       "      <td>0</td>\n",
       "      <td>2013370946</td>\n",
       "      <td>Tue Jun 02 22:30:58 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>xRawrLexxiex</td>\n",
       "      <td>@MileyJack same.. &amp;amp; I jus got back from a camp. Im so TIRED &amp;amp; kinda messedup cuz my bestie is movin to Australia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        polarity          id                      datetime     query  \\\n",
       "333551         0  2013370946  Tue Jun 02 22:30:58 PDT 2009  NO_QUERY   \n",
       "\n",
       "            username  \\\n",
       "333551  xRawrLexxiex   \n",
       "\n",
       "                                                                                                                          content  \n",
       "333551  @MileyJack same.. &amp; I jus got back from a camp. Im so TIRED &amp; kinda messedup cuz my bestie is movin to Australia   "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = words_df\n",
    "y = sample.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that `X` has 20,000 rows and 2,000 columns, and that `y` has 20,000 rows of 1 column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking an algorithm\n",
    "\n",
    "What kind of algorithm do we want? We've used quite a few, and I just pulled another one couple classifiers of thin air."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When picking an algorithm, think about what the output should be: is it a category? A probability, an amount? In this case **it might be any of those!**\n",
    "\n",
    "For example:\n",
    "\n",
    "* **A category:** `0` or `1` for negative vs positive\n",
    "* **A probability:** The % chance that it's either negative or positive (between 0 and 1)\n",
    "* **An amount:** A score between 0 and 1 about how positive it is\n",
    "\n",
    "So hey, let's just make **one of each** of these. Name them `linreg`, `logreg`, `forest`, `svc`, and `bayes`.\n",
    "\n",
    "The two new ones - `LinearSVC` and `MultinomialNB` - work exactly the same as your other classifiers, you'll be doing the standard creation and fitting:\n",
    "\n",
    "```python\n",
    "svc = LinearSVC()\n",
    "svc.fit(X, y)\n",
    "```\n",
    "\n",
    "**Create and train classifiers in the cells below.** Add `%%time` to the top of each cell to see how long they take to train.\n",
    "\n",
    "* **Tip:** Remember you need to add `C=1e9` to logistic regression, and specify the solver!\n",
    "* **Tip:** If the logistic regression doesn't converge, it hasn't found an answer. You might need to increase `max_iter` (the default is 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.5 s, sys: 1.6 s, total: 24.1 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a linear regression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.2 s, sys: 789 ms, total: 50 s\n",
      "Wall time: 27.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a logistic regression - if it doesn't converge be sure to increase max_iter\n",
    "\n",
    "logreg = LogisticRegression(C=1e9, solver='lbfgs', max_iter=1000)\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 s, sys: 197 ms, total: 11.7 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a random forest classifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=10)\n",
    "forest.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LINEAR SVC (linear support vector classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 235 ms, sys: 16.1 ms, total: 251 ms\n",
      "Wall time: 279 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a linear support vector classifier (LinearSVC)\n",
    "\n",
    "svc = LinearSVC()\n",
    "svc.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 200 ms, sys: 34.9 ms, total: 235 ms\n",
      "Wall time: 207 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a multinomial naive bayes classifier (MultinomialNB)\n",
    "\n",
    "bayes = MultinomialNB()\n",
    "bayes.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How long did each take to train?** How much faster were some compared to others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes was fastest! It ranged from less than a second to almost 30 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use our models on some new data\n",
    "\n",
    "Now that we've trained our models, **they can try to predict whether a model is positive or negative**.\n",
    "\n",
    "**Add five more sentences to the list below.** They should be a mix of positive and negative. They can be boring, they can be exciting, they can be short, they can be long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm not sure how I feel about toast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did you see the baseball game yesterday?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The package was delivered late and the contents were broken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trashy television shows are some of my favorites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm seeing a Kubrick film tomorrow, I hear not so great things about it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I find chirping birds irritating, but I know I'm not the only one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>These cakes are too sweet for me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It's hot today but I'm so glad it's finally sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Doors in the US are impossible to open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Homework is challenging and I learn a lot from it. But it could be better.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       content\n",
       "0                                          I'm not sure how I feel about toast\n",
       "1                                     Did you see the baseball game yesterday?\n",
       "2                  The package was delivered late and the contents were broken\n",
       "3                             Trashy television shows are some of my favorites\n",
       "4     I'm seeing a Kubrick film tomorrow, I hear not so great things about it.\n",
       "5            I find chirping birds irritating, but I know I'm not the only one\n",
       "6                                                                    I'm bored\n",
       "7                                             These cakes are too sweet for me\n",
       "8                            It's hot today but I'm so glad it's finally sunny\n",
       "9                                       Doors in the US are impossible to open\n",
       "10  Homework is challenging and I learn a lot from it. But it could be better."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create some test data\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "unknown = pd.DataFrame([\n",
    "       \"I'm not sure how I feel about toast\",\n",
    "       \"Did you see the baseball game yesterday?\",\n",
    "       \"The package was delivered late and the contents were broken\",\n",
    "       \"Trashy television shows are some of my favorites\",\n",
    "       \"I'm seeing a Kubrick film tomorrow, I hear not so great things about it.\",\n",
    "       \"I find chirping birds irritating, but I know I'm not the only one\",\n",
    "        \"I'm bored\",\n",
    "    \"These cakes are too sweet for me\",\n",
    "    \"It's hot today but I'm so glad it's finally sunny\",\n",
    "    \"Doors in the US are impossible to open\",\n",
    "    \"Homework is challenging and I learn a lot from it. But it could be better.\"], columns=['content'])\n",
    "unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to **vectorizer** our sentences into numbers, so the algorithm can understand them.\n",
    "\n",
    "Our algorithm only knows **certain words.** Run `vectorizer.get_feature_names()` to show you the list of the words it knows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '09',\n",
       " '10',\n",
       " '100',\n",
       " '11',\n",
       " '12',\n",
       " '140',\n",
       " '15',\n",
       " '17',\n",
       " '18',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2009',\n",
       " '21',\n",
       " '24',\n",
       " '25',\n",
       " '2day',\n",
       " '2nd',\n",
       " '2nite',\n",
       " '30',\n",
       " '33',\n",
       " '3d',\n",
       " '3g',\n",
       " '40',\n",
       " '45',\n",
       " '50',\n",
       " '7am',\n",
       " '80',\n",
       " 'able',\n",
       " 'about',\n",
       " 'absolutely',\n",
       " 'abt',\n",
       " 'access',\n",
       " 'account',\n",
       " 'ache',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'actually',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'adorable',\n",
       " 'advice',\n",
       " 'afford',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'ages',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'ah',\n",
       " 'ahaha',\n",
       " 'ahead',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'album',\n",
       " 'alex',\n",
       " 'all',\n",
       " 'allowed',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'america',\n",
       " 'american',\n",
       " 'amp',\n",
       " 'an',\n",
       " 'and',\n",
       " 'angel',\n",
       " 'angels',\n",
       " 'angry',\n",
       " 'annoying',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apartment',\n",
       " 'app',\n",
       " 'apparently',\n",
       " 'apple',\n",
       " 'appreciate',\n",
       " 'appt',\n",
       " 'are',\n",
       " 'area',\n",
       " 'aren',\n",
       " 'argh',\n",
       " 'arm',\n",
       " 'around',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'art',\n",
       " 'article',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asleep',\n",
       " 'ass',\n",
       " 'aswell',\n",
       " 'at',\n",
       " 'ate',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'australia',\n",
       " 'avatar',\n",
       " 'aw',\n",
       " 'awake',\n",
       " 'awards',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awh',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'aww',\n",
       " 'awww',\n",
       " 'awwww',\n",
       " 'awwwww',\n",
       " 'b4',\n",
       " 'babe',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'background',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'bag',\n",
       " 'bah',\n",
       " 'ball',\n",
       " 'banana',\n",
       " 'band',\n",
       " 'bands',\n",
       " 'bank',\n",
       " 'bar',\n",
       " 'barely',\n",
       " 'basically',\n",
       " 'battery',\n",
       " 'bay',\n",
       " 'bb',\n",
       " 'bbq',\n",
       " 'bc',\n",
       " 'bday',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'bear',\n",
       " 'beat',\n",
       " 'beautiful',\n",
       " 'because',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'beer',\n",
       " 'before',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'ben',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'better',\n",
       " 'between',\n",
       " 'bf',\n",
       " 'bff',\n",
       " 'bgt',\n",
       " 'big',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bill',\n",
       " 'biology',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'black',\n",
       " 'blackberry',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'blast',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blip',\n",
       " 'block',\n",
       " 'blocked',\n",
       " 'blog',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'body',\n",
       " 'boo',\n",
       " 'book',\n",
       " 'books',\n",
       " 'boom',\n",
       " 'boooo',\n",
       " 'bored',\n",
       " 'boring',\n",
       " 'boss',\n",
       " 'both',\n",
       " 'bought',\n",
       " 'bound',\n",
       " 'bout',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'boyle',\n",
       " 'boys',\n",
       " 'brain',\n",
       " 'brazil',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakfast',\n",
       " 'breaking',\n",
       " 'breaks',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'bro',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'brothers',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'btw',\n",
       " 'buddy',\n",
       " 'bug',\n",
       " 'building',\n",
       " 'bummed',\n",
       " 'bummer',\n",
       " 'bunch',\n",
       " 'burn',\n",
       " 'burnt',\n",
       " 'bus',\n",
       " 'business',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'butt',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'by',\n",
       " 'bye',\n",
       " 'ca',\n",
       " 'cake',\n",
       " 'cali',\n",
       " 'california',\n",
       " 'call',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'can',\n",
       " 'canada',\n",
       " 'cancelled',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'case',\n",
       " 'cast',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'catching',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'cavs',\n",
       " 'cd',\n",
       " 'celebrate',\n",
       " 'cell',\n",
       " 'center',\n",
       " 'certainly',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'channel',\n",
       " 'character',\n",
       " 'characters',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'checking',\n",
       " 'cheer',\n",
       " 'cheese',\n",
       " 'chicago',\n",
       " 'chicken',\n",
       " 'children',\n",
       " 'chill',\n",
       " 'chillin',\n",
       " 'chinese',\n",
       " 'chocolate',\n",
       " 'choice',\n",
       " 'chris',\n",
       " 'chuck',\n",
       " 'church',\n",
       " 'city',\n",
       " 'class',\n",
       " 'classes',\n",
       " 'classic',\n",
       " 'clean',\n",
       " 'cleaned',\n",
       " 'cleaning',\n",
       " 'clear',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closer',\n",
       " 'clothes',\n",
       " 'cloudy',\n",
       " 'club',\n",
       " 'co',\n",
       " 'coast',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'cold',\n",
       " 'college',\n",
       " 'color',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comin',\n",
       " 'coming',\n",
       " 'comment',\n",
       " 'comments',\n",
       " 'comp',\n",
       " 'company',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'computer',\n",
       " 'conan',\n",
       " 'concert',\n",
       " 'conference',\n",
       " 'confused',\n",
       " 'congrats',\n",
       " 'congratulations',\n",
       " 'connect',\n",
       " 'connection',\n",
       " 'contact',\n",
       " 'content',\n",
       " 'continue',\n",
       " 'cook',\n",
       " 'cookies',\n",
       " 'cooking',\n",
       " 'cool',\n",
       " 'coolest',\n",
       " 'copy',\n",
       " 'corner',\n",
       " 'cos',\n",
       " 'couch',\n",
       " 'cough',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'couldnt',\n",
       " 'count',\n",
       " 'counting',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'cousin',\n",
       " 'cousins',\n",
       " 'coz',\n",
       " 'crack',\n",
       " 'crap',\n",
       " 'craving',\n",
       " 'crazy',\n",
       " 'cream',\n",
       " 'creative',\n",
       " 'cried',\n",
       " 'crossed',\n",
       " 'cry',\n",
       " 'crying',\n",
       " 'cup',\n",
       " 'cupcakes',\n",
       " 'curious',\n",
       " 'currently',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cutting',\n",
       " 'cuz',\n",
       " 'cyrus',\n",
       " 'da',\n",
       " 'dad',\n",
       " 'daddy',\n",
       " 'dallas',\n",
       " 'dam',\n",
       " 'dammit',\n",
       " 'damn',\n",
       " 'dance',\n",
       " 'dancing',\n",
       " 'dang',\n",
       " 'danny',\n",
       " 'dannygokey',\n",
       " 'dark',\n",
       " 'darn',\n",
       " 'dat',\n",
       " 'data',\n",
       " 'date',\n",
       " 'dates',\n",
       " 'daughter',\n",
       " 'dave',\n",
       " 'david',\n",
       " 'davidarchie',\n",
       " 'day',\n",
       " 'days',\n",
       " 'dc',\n",
       " 'ddlovato',\n",
       " 'de',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'decided',\n",
       " 'decision',\n",
       " 'deep',\n",
       " 'def',\n",
       " 'definately',\n",
       " 'definitely',\n",
       " 'delete',\n",
       " 'deleted',\n",
       " 'delongeday',\n",
       " 'demi',\n",
       " 'demons',\n",
       " 'dentist',\n",
       " 'depressed',\n",
       " 'depressing',\n",
       " 'deserve',\n",
       " 'design',\n",
       " 'desk',\n",
       " 'details',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'didnt',\n",
       " 'die',\n",
       " 'died',\n",
       " 'diet',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'dinner',\n",
       " 'direct',\n",
       " 'disappointed',\n",
       " 'disney',\n",
       " 'diversity',\n",
       " 'dm',\n",
       " 'dnt',\n",
       " 'do',\n",
       " 'doctor',\n",
       " 'doctors',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doesnt',\n",
       " 'dog',\n",
       " 'dogs',\n",
       " 'doin',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'done',\n",
       " 'donniewahlberg',\n",
       " 'dont',\n",
       " 'door',\n",
       " 'double',\n",
       " 'doubt',\n",
       " 'dougiemcfly',\n",
       " 'down',\n",
       " 'download',\n",
       " 'downloaded',\n",
       " 'downtown',\n",
       " 'dr',\n",
       " 'drag',\n",
       " 'dream',\n",
       " 'dreams',\n",
       " 'dress',\n",
       " 'drink',\n",
       " 'drinking',\n",
       " 'drinks',\n",
       " 'drive',\n",
       " 'driving',\n",
       " 'drop',\n",
       " 'dropped',\n",
       " 'drunk',\n",
       " 'dry',\n",
       " 'dude',\n",
       " 'due',\n",
       " 'dumb',\n",
       " 'dunno',\n",
       " 'during',\n",
       " 'dvd',\n",
       " 'dying',\n",
       " 'each',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'earth',\n",
       " 'easier',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'eaten',\n",
       " 'eating',\n",
       " 'ebay',\n",
       " 'eh',\n",
       " 'either',\n",
       " 'else',\n",
       " 'em',\n",
       " 'email',\n",
       " 'empty',\n",
       " 'end',\n",
       " 'ended',\n",
       " 'energy',\n",
       " 'england',\n",
       " 'english',\n",
       " 'enjoy',\n",
       " 'enjoyed',\n",
       " 'enjoying',\n",
       " 'enough',\n",
       " 'epic',\n",
       " 'episode',\n",
       " 'error',\n",
       " 'especially',\n",
       " 'etc',\n",
       " 'europe',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'event',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyday',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'ex',\n",
       " 'exactly',\n",
       " 'exam',\n",
       " 'exams',\n",
       " 'excellent',\n",
       " 'except',\n",
       " 'excited',\n",
       " 'exciting',\n",
       " 'exhausted',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'extra',\n",
       " 'extremely',\n",
       " 'eye',\n",
       " 'eyes',\n",
       " 'fab',\n",
       " 'fabulous',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'fact',\n",
       " 'fail',\n",
       " 'failed',\n",
       " 'fair',\n",
       " 'fake',\n",
       " 'fall',\n",
       " 'falling',\n",
       " 'fam',\n",
       " 'family',\n",
       " 'fan',\n",
       " 'fans',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'faster',\n",
       " 'fat',\n",
       " 'father',\n",
       " 'fathers',\n",
       " 'fault',\n",
       " 'fav',\n",
       " 'fave',\n",
       " 'favorite',\n",
       " 'favourite',\n",
       " 'fb',\n",
       " 'fear',\n",
       " 'feed',\n",
       " 'feel',\n",
       " 'feelin',\n",
       " 'feeling',\n",
       " 'feels',\n",
       " 'feet',\n",
       " 'fell',\n",
       " 'felt',\n",
       " 'festival',\n",
       " 'fever',\n",
       " 'few',\n",
       " 'ff',\n",
       " 'field',\n",
       " 'fight',\n",
       " 'figure',\n",
       " 'figured',\n",
       " 'files',\n",
       " 'film',\n",
       " 'final',\n",
       " 'finale',\n",
       " 'finally',\n",
       " 'finals',\n",
       " 'find',\n",
       " 'finding',\n",
       " 'fine',\n",
       " 'finger',\n",
       " 'fingers',\n",
       " 'finish',\n",
       " 'finished',\n",
       " 'finishing',\n",
       " 'fire',\n",
       " 'first',\n",
       " 'fish',\n",
       " 'fit',\n",
       " 'five',\n",
       " 'fix',\n",
       " 'fixed',\n",
       " 'flat',\n",
       " 'flickr',\n",
       " 'flight',\n",
       " 'florida',\n",
       " 'flowers',\n",
       " 'flu',\n",
       " 'fly',\n",
       " 'flying',\n",
       " 'fm',\n",
       " 'fml',\n",
       " 'folks',\n",
       " 'follow',\n",
       " 'followed',\n",
       " 'follower',\n",
       " 'followers',\n",
       " 'followfriday',\n",
       " 'following',\n",
       " 'food',\n",
       " 'football',\n",
       " 'for',\n",
       " 'forever',\n",
       " 'forget',\n",
       " 'forgot',\n",
       " 'form',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'four',\n",
       " 'france',\n",
       " 'freakin',\n",
       " 'freaking',\n",
       " 'free',\n",
       " 'freezing',\n",
       " 'french',\n",
       " 'fresh',\n",
       " 'friday',\n",
       " 'friend',\n",
       " 'friendly',\n",
       " 'friends',\n",
       " 'from',\n",
       " 'front',\n",
       " 'fruit',\n",
       " 'frustrating',\n",
       " 'fuck',\n",
       " 'fucked',\n",
       " 'fuckin',\n",
       " 'fucking',\n",
       " 'full',\n",
       " 'fun',\n",
       " 'funny',\n",
       " 'future',\n",
       " 'gaga',\n",
       " 'gah',\n",
       " 'game',\n",
       " 'games',\n",
       " 'garden',\n",
       " 'gave',\n",
       " 'gay',\n",
       " 'gd',\n",
       " 'germany',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'gettin',\n",
       " 'getting',\n",
       " 'gig',\n",
       " 'girl',\n",
       " 'girlfriend',\n",
       " 'girls',\n",
       " 'give',\n",
       " 'given',\n",
       " 'giving',\n",
       " 'glad',\n",
       " 'glasses',\n",
       " 'go',\n",
       " 'god',\n",
       " 'goes',\n",
       " 'goin',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'gonna',\n",
       " 'good',\n",
       " 'goodbye',\n",
       " 'goodness',\n",
       " 'goodnight',\n",
       " 'google',\n",
       " 'gorgeous',\n",
       " 'gosh',\n",
       " 'gossip',\n",
       " 'got',\n",
       " 'gotta',\n",
       " 'gotten',\n",
       " 'grad',\n",
       " 'grade',\n",
       " 'graduation',\n",
       " 'grandma',\n",
       " 'grass',\n",
       " 'great',\n",
       " 'green',\n",
       " 'group',\n",
       " 'grow',\n",
       " 'gt',\n",
       " 'guess',\n",
       " 'guitar',\n",
       " 'gunna',\n",
       " 'gutted',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'gym',\n",
       " 'ha',\n",
       " 'had',\n",
       " 'hah',\n",
       " 'haha',\n",
       " 'hahah',\n",
       " 'hahaha',\n",
       " 'hahahaha',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'hands',\n",
       " 'hang',\n",
       " 'hanging',\n",
       " 'hangover',\n",
       " 'hannah',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happening',\n",
       " 'happens',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'harry',\n",
       " 'has',\n",
       " 'hasn',\n",
       " 'hat',\n",
       " 'hate',\n",
       " 'hates',\n",
       " 'hav',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'havent',\n",
       " 'having',\n",
       " 'hawaii',\n",
       " 'he',\n",
       " 'head',\n",
       " 'headache',\n",
       " 'headed',\n",
       " 'heading',\n",
       " 'health',\n",
       " 'healthy',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'hearing',\n",
       " 'heart',\n",
       " 'heat',\n",
       " 'heck',\n",
       " 'hee',\n",
       " 'hehe',\n",
       " 'hehehe',\n",
       " 'hell',\n",
       " 'hella',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'helping',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hero',\n",
       " 'hes',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'high',\n",
       " 'hilarious',\n",
       " 'hills',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'hip',\n",
       " 'his',\n",
       " 'history',\n",
       " 'hit',\n",
       " 'hmm',\n",
       " 'hmmm',\n",
       " 'hold',\n",
       " 'hole',\n",
       " 'holiday',\n",
       " 'holy',\n",
       " 'home',\n",
       " 'homework',\n",
       " 'honestly',\n",
       " 'honey',\n",
       " 'hoo',\n",
       " 'hope',\n",
       " 'hopefully',\n",
       " 'hopes',\n",
       " 'hoping',\n",
       " 'horrible',\n",
       " 'hospital',\n",
       " 'hot',\n",
       " 'hotel',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'houston',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hrs',\n",
       " 'html',\n",
       " 'http',\n",
       " 'hubby',\n",
       " 'hug',\n",
       " 'huge',\n",
       " 'hugs',\n",
       " 'huh',\n",
       " 'hun',\n",
       " 'hungry',\n",
       " 'hunting',\n",
       " 'hurry',\n",
       " 'hurt',\n",
       " 'hurting',\n",
       " 'hurts',\n",
       " 'husband',\n",
       " 'hw',\n",
       " 'ice',\n",
       " 'id',\n",
       " 'idea',\n",
       " 'ideas',\n",
       " 'idk',\n",
       " 'idol',\n",
       " 'if',\n",
       " 'ii',\n",
       " 'ill',\n",
       " 'im',\n",
       " 'ima',\n",
       " 'imagine',\n",
       " 'important',\n",
       " 'impossible',\n",
       " 'impressed',\n",
       " 'in',\n",
       " 'indeed',\n",
       " 'info',\n",
       " 'information',\n",
       " 'ing',\n",
       " 'inside',\n",
       " 'install',\n",
       " 'instead',\n",
       " 'interested',\n",
       " 'interesting',\n",
       " 'internet',\n",
       " 'interview',\n",
       " 'into',\n",
       " 'invite',\n",
       " 'iphone',\n",
       " 'ipod',\n",
       " 'is',\n",
       " 'island',\n",
       " 'isn',\n",
       " 'isnt',\n",
       " 'issue',\n",
       " 'issues',\n",
       " 'it',\n",
       " 'italian',\n",
       " 'italy',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'itunes',\n",
       " 'iv',\n",
       " 'ive',\n",
       " 'iÃ¢',\n",
       " 'jack',\n",
       " 'james',\n",
       " 'jason',\n",
       " 'jay',\n",
       " 'jb',\n",
       " 'jealous',\n",
       " 'jersey',\n",
       " 'jesus',\n",
       " 'jk',\n",
       " 'job',\n",
       " 'joe',\n",
       " 'john',\n",
       " 'johnny',\n",
       " 'join',\n",
       " 'joke',\n",
       " 'jon',\n",
       " 'jonas',\n",
       " 'jonasbrothers',\n",
       " 'jonathanrknight',\n",
       " 'jordanknight',\n",
       " 'joy',\n",
       " 'juice',\n",
       " 'july',\n",
       " 'june',\n",
       " 'jus',\n",
       " 'just',\n",
       " 'kate',\n",
       " 'keep',\n",
       " 'keeping',\n",
       " 'keeps',\n",
       " 'kevin',\n",
       " 'keyboard',\n",
       " 'kick',\n",
       " 'kid',\n",
       " 'kidding',\n",
       " 'kids',\n",
       " 'kill',\n",
       " 'killed',\n",
       " 'killer',\n",
       " 'killing',\n",
       " 'kind',\n",
       " 'kinda',\n",
       " 'king',\n",
       " 'kings',\n",
       " 'kiss',\n",
       " 'kisses',\n",
       " 'kitchen',\n",
       " 'kitty',\n",
       " 'knee',\n",
       " 'knew',\n",
       " 'kno',\n",
       " 'knocked',\n",
       " 'know',\n",
       " 'knowing',\n",
       " 'knows',\n",
       " 'ko',\n",
       " 'la',\n",
       " 'lack',\n",
       " 'ladies',\n",
       " 'lady',\n",
       " 'lake',\n",
       " 'lakers',\n",
       " 'lame',\n",
       " 'land',\n",
       " 'landed',\n",
       " 'lang',\n",
       " 'language',\n",
       " 'laptop',\n",
       " 'last',\n",
       " 'late',\n",
       " 'lately',\n",
       " 'later',\n",
       " 'latest',\n",
       " 'laugh',\n",
       " 'laughing',\n",
       " 'laundry',\n",
       " 'lauren',\n",
       " 'law',\n",
       " 'lay',\n",
       " 'laying',\n",
       " 'lazy',\n",
       " 'le',\n",
       " 'learn',\n",
       " 'learning',\n",
       " 'least',\n",
       " 'leave',\n",
       " 'leaves',\n",
       " 'leaving',\n",
       " 'lee',\n",
       " 'left',\n",
       " 'leg',\n",
       " 'legs',\n",
       " 'less',\n",
       " 'let',\n",
       " 'lets',\n",
       " ...]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually when we use the vectorizer, we write code like this:\n",
    "    \n",
    "```python\n",
    "vectors = vectorizer.fit_transform(....)\n",
    "```\n",
    "\n",
    "Which both learns all the words **and** counts them. In this case **we already have the list of words we know, we only want to count them.** So instead of `.fit_transform`, we just use `.transform`:\n",
    "\n",
    "```python\n",
    "unknown_vectors = vectorizer.transform(unknown.content)\n",
    "unknown_words_df = ......\n",
    "```\n",
    "\n",
    "Finish making your `unknown_words_df` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>140</th>\n",
       "      <th>15</th>\n",
       "      <th>17</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yu</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000   09   10  100   11   12  140   15   17  ...  youre  yours  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "\n",
       "   yourself  youtube   yr   yu  yum  yummy  yup  zoo  \n",
       "0       0.0      0.0  0.0  0.0  0.0    0.0  0.0  0.0  \n",
       "1       0.0      0.0  0.0  0.0  0.0    0.0  0.0  0.0  \n",
       "\n",
       "[2 rows x 2000 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_vectors = vectorizer.transform(unknown.content)\n",
    "unknown_words_df = pd.DataFrame(unknown_vectors.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "unknown_words_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm `unknown_words_df` is 11 rows and 2,000 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 2000)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_words_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting with our models\n",
    "\n",
    "To make a prediction for each of our sentences, you can use `.predict` with each of our models. For example, it would look like this for linear regression:\n",
    "\n",
    "```python\n",
    "unknown['pred_linreg'] = linreg.predict(unknown_words_df)\n",
    "```\n",
    "\n",
    "To add the prediction for logistic regression, you'd run similar `.predict` code, which will give you a `0` (negative) or a `1` (positive). A difference between the two is that for logistic regression, you can **also ask for the probability that the sentence is in the `1` category** instead of just simply the category. To do that, you use this code:\n",
    "\n",
    "```python\n",
    "unknown['pred_logreg_prob'] = linreg.predict_proba(unknown_words_df)[:,1]\n",
    "```\n",
    "\n",
    "**Add new columns for each of the models you trained.** If the model has a `.predict_proba`, add that as a column as well. \n",
    "\n",
    "* **Tip:** Tab is helpful for knowing whether `.predict_proba` is an option.\n",
    "* **Tip:** Don't forget the `[:,1]` after `.predict_proba`, it means \"give me the probability for category `1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown['pred_linreg'] = linreg.predict(unknown_words_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown['pred_logreg'] = logreg.predict(unknown_words_df)\n",
    "unknown['pred_logreg_prob'] = logreg.predict_proba(unknown_words_df)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown['pred_forest'] = forest.predict(unknown_words_df)\n",
    "unknown['pred_forest_prob'] = forest.predict_proba(unknown_words_df)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LINEAR SVC (linear support vector classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown['pred_svc'] = svc.predict(unknown_words_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown['pred_bayes'] = bayes.predict(unknown_words_df)\n",
    "unknown['pred_bayes_prob'] = bayes.predict_proba(unknown_words_df)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>pred_linreg</th>\n",
       "      <th>pred_logreg</th>\n",
       "      <th>pred_logreg_prob</th>\n",
       "      <th>pred_forest</th>\n",
       "      <th>pred_forest_prob</th>\n",
       "      <th>pred_svc</th>\n",
       "      <th>pred_bayes</th>\n",
       "      <th>pred_bayes_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm not sure how I feel about toast</td>\n",
       "      <td>0.259243</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140921</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.39402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               content  pred_linreg  pred_logreg  \\\n",
       "0  I'm not sure how I feel about toast     0.259243            0   \n",
       "\n",
       "   pred_logreg_prob  pred_forest  pred_forest_prob  pred_svc  pred_bayes  \\\n",
       "0          0.140921            0             0.125         0           0   \n",
       "\n",
       "   pred_bayes_prob  \n",
       "0          0.39402  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should look something like the below. Check your column names to confirm they match up.\n",
    "\n",
    "|content|pred_linreg|pred_logreg|pred_logreg_proba|pred_forest|pred_forest_proba|pred_svc|pred_bayes|pred_bayes_proba|\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "|I'm not sure how I feel about toast|0.342560|0|0.271403|0|0.5|0|0|0.425271|\n",
    "|...|...|...|...|...|...|...|...|...|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A category: 0 or 1 for negative vs positive\n",
    "# A probability: The % chance that it's either negative or positive (between 0 and 1)\n",
    "# An amount: A score between 0 and 1 about how positive it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: What do the numbers mean? What's the difference between a 0 and a 1? A 0.5? Negative numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Negative: The larger the negative, the more likely it is that the result is negative\n",
    "0 - 1: probability that the sentence is in the 1 category\n",
    "0.5: 50% chance that it's positive\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Were there any sentences where the classifiers seemed to disagree about? How do you feel about the amount they disagree? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>pred_linreg</th>\n",
       "      <th>pred_logreg</th>\n",
       "      <th>pred_logreg_prob</th>\n",
       "      <th>pred_forest</th>\n",
       "      <th>pred_forest_prob</th>\n",
       "      <th>pred_svc</th>\n",
       "      <th>pred_bayes</th>\n",
       "      <th>pred_bayes_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm not sure how I feel about toast</td>\n",
       "      <td>0.259243</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140921</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.394020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did you see the baseball game yesterday?</td>\n",
       "      <td>0.592017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632144</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.568487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The package was delivered late and the contents were broken</td>\n",
       "      <td>0.183707</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117520</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trashy television shows are some of my favorites</td>\n",
       "      <td>0.551175</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621079</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm seeing a Kubrick film tomorrow, I hear not so great things about it.</td>\n",
       "      <td>0.596936</td>\n",
       "      <td>1</td>\n",
       "      <td>0.623719</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.625602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I find chirping birds irritating, but I know I'm not the only one</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041410</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.302074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm bored</td>\n",
       "      <td>0.158886</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.267935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>These cakes are too sweet for me</td>\n",
       "      <td>0.685562</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.688084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It's hot today but I'm so glad it's finally sunny</td>\n",
       "      <td>0.997111</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966330</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.691871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Doors in the US are impossible to open</td>\n",
       "      <td>0.204941</td>\n",
       "      <td>0</td>\n",
       "      <td>0.123637</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.363001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Homework is challenging and I learn a lot from it. But it could be better.</td>\n",
       "      <td>0.498259</td>\n",
       "      <td>0</td>\n",
       "      <td>0.448782</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.421987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       content  \\\n",
       "0                                          I'm not sure how I feel about toast   \n",
       "1                                     Did you see the baseball game yesterday?   \n",
       "2                  The package was delivered late and the contents were broken   \n",
       "3                             Trashy television shows are some of my favorites   \n",
       "4     I'm seeing a Kubrick film tomorrow, I hear not so great things about it.   \n",
       "5            I find chirping birds irritating, but I know I'm not the only one   \n",
       "6                                                                    I'm bored   \n",
       "7                                             These cakes are too sweet for me   \n",
       "8                            It's hot today but I'm so glad it's finally sunny   \n",
       "9                                       Doors in the US are impossible to open   \n",
       "10  Homework is challenging and I learn a lot from it. But it could be better.   \n",
       "\n",
       "    pred_linreg  pred_logreg  pred_logreg_prob  pred_forest  pred_forest_prob  \\\n",
       "0      0.259243            0          0.140921            0          0.125000   \n",
       "1      0.592017            1          0.632144            1          0.533333   \n",
       "2      0.183707            0          0.117520            0          0.500000   \n",
       "3      0.551175            1          0.621079            0          0.100000   \n",
       "4      0.596936            1          0.623719            0          0.300000   \n",
       "5     -0.001061            0          0.041410            0          0.300000   \n",
       "6      0.158886            0          0.112667            0          0.000000   \n",
       "7      0.685562            1          0.885021            1          0.800000   \n",
       "8      0.997111            1          0.966330            1          0.700000   \n",
       "9      0.204941            0          0.123637            1          0.800000   \n",
       "10     0.498259            0          0.448782            1          0.900000   \n",
       "\n",
       "    pred_svc  pred_bayes  pred_bayes_prob  \n",
       "0          0           0         0.394020  \n",
       "1          1           1         0.568487  \n",
       "2          0           0         0.278444  \n",
       "3          1           1         0.556308  \n",
       "4          1           1         0.625602  \n",
       "5          0           0         0.302074  \n",
       "6          0           0         0.267935  \n",
       "7          1           1         0.688084  \n",
       "8          1           1         0.691871  \n",
       "9          0           0         0.363001  \n",
       "10         0           0         0.421987  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\"I find chirping birds irritating, but I know I'm not the only one\":\n",
    "Linreg thinks it's negative, but others predict it's more likely to be positive.\n",
    "Going from slightly negative to 0.3 seems like a significant margin of error\n",
    "'''    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: What's the difference between using a 0/1 to talk about sentiment compared to 0-1? When might you use one compared to another?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "0/1: boolean/categorical. Negative OR positive\n",
    "0-1: probability, from 0 to 100%\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: What's the difference between the linear regression model and the other models we're using? Why might it fit or not fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLinear regression gives you a numeric result. Other models give you categorical results.\\nIn this case, we can think of \"negative vs positive\" as categorical (positive vs negative) OR \\nnumeric (0-100, 0 = negative, 100 = positive) etc\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Linear regression gives you a numeric result. Other models give you categorical results.\n",
    "In this case, we can think of \"negative vs positive\" as categorical (positive vs negative) OR \n",
    "numeric (0-100, 0 = negative, 100 = positive) etc\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: Between 0-1, what range do you think counts as \"negative,\" \"positive\" and \"neutral\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-30: negative\n",
    "# 30-69: neutral\n",
    "# 70+: positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9: Does the variation in scores reflect the variation you would see among people? Or is it better or worse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think the variation is more arbitrary than what I would see among people. It seems worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maybe we should have tested this?\n",
    "\n",
    "We can actually see **which model performs the best**. Let's remind ourselves what we have by looking at:\n",
    "\n",
    "* `X`\n",
    "* `y`\n",
    "* `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>140</th>\n",
       "      <th>15</th>\n",
       "      <th>17</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yu</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000   09   10  100   11   12  140   15   17  ...  youre  yours  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "\n",
       "   yourself  youtube   yr   yu  yum  yummy  yup  zoo  \n",
       "0       0.0      0.0  0.0  0.0  0.0    0.0  0.0  0.0  \n",
       "1       0.0      0.0  0.0  0.0  0.0    0.0  0.0  0.0  \n",
       "2       0.0      0.0  0.0  0.0  0.0    0.0  0.0  0.0  \n",
       "\n",
       "[3 rows x 2000 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333551     0\n",
       "1464028    1\n",
       "786571     0\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity          id                      datetime     query  \\\n",
       "0         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "\n",
       "          username  \\\n",
       "0  _TheSpecialOne_   \n",
       "1    scotthamilton   \n",
       "2         mattycus   \n",
       "\n",
       "                                                                                                               content  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "1      is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!  \n",
       "2                            @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original dataframe is a list of many, many tweets. We turned this into `X` - vectorized words - and `y` - whether the tweet is negative or positive.\n",
    "\n",
    "Before we used `.fit(X, y)` to train on all of our data. Instead, **we can test our models** by doing a test/train split and see if the predictions match the actual labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test and training data \n",
    "\n",
    "Split your `X` and `y` into train and test datasets. I always have to look up how to do it, so here's the code for you:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn sample into df\n",
    "df = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `X_train` and `y_train` to train all your models, except the linear regression one. You should be training:\n",
    "\n",
    "* `logreg`\n",
    "* `forest`\n",
    "* `svc`\n",
    "* `bayes`\n",
    "\n",
    "Again, do them each in **separate cells** and use `%%time` to see how long each one takes to learn what's a positive vs negative tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.2 s, sys: 969 ms, total: 59.1 s\n",
      "Wall time: 34.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a logistic regression - if it doesn't converge be sure to increase max_iter\n",
    "\n",
    "logreg = LogisticRegression(C=1e9, solver='lbfgs', max_iter=1000)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.13 s, sys: 140 ms, total: 7.27 s\n",
      "Wall time: 7.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a random forest classifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=10)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LINEAR SVC (linear support vector classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 202 ms, sys: 16.2 ms, total: 218 ms\n",
      "Wall time: 253 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a linear support vector classifier (LinearSVC)\n",
    "\n",
    "svc = LinearSVC()\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 172 ms, sys: 38.1 ms, total: 210 ms\n",
      "Wall time: 217 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a multinomial naive bayes classifier (MultinomialNB)\n",
    "\n",
    "bayes = MultinomialNB()\n",
    "bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrices\n",
    "\n",
    "To see how well they did, we'll use a confusion matrix for each one. For example, here is what you'll use for logistic regression:\n",
    "\n",
    "```python\n",
    "y_true = y_test\n",
    "y_pred = logreg.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>1829</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>630</td>\n",
       "      <td>1844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative                1829                 697\n",
       "Is positive                 630                1844"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = logreg.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>1861</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>829</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative                1861                 665\n",
       "Is positive                 829                1645"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = forest.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>1867</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>592</td>\n",
       "      <td>1882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative                1867                 659\n",
       "Is positive                 592                1882"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = svc.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>1934</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>665</td>\n",
       "      <td>1809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative                1934                 592\n",
       "Is positive                 665                1809"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = bayes.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage-based confusion matrices\n",
    "\n",
    "Those are kind of irritating in that they're just numbers. It might work better if you do something like this instead to get percentages:\n",
    "\n",
    "```python\n",
    "y_true = y_test\n",
    "y_pred = logreg.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names) / matrix.sum(axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logisitic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>0.724070</td>\n",
       "      <td>0.281730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>0.249406</td>\n",
       "      <td>0.745352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative            0.724070            0.281730\n",
       "Is positive            0.249406            0.745352"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = logreg.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names) / matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>0.736738</td>\n",
       "      <td>0.268795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>0.328187</td>\n",
       "      <td>0.664915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative            0.736738            0.268795\n",
       "Is positive            0.328187            0.664915"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = forest.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names) / matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>0.739113</td>\n",
       "      <td>0.266370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>0.234363</td>\n",
       "      <td>0.760711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative            0.739113            0.266370\n",
       "Is positive            0.234363            0.760711"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = svc.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names) / matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>0.765637</td>\n",
       "      <td>0.239289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>0.263262</td>\n",
       "      <td>0.731205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative            0.765637            0.239289\n",
       "Is positive            0.263262            0.731205"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = bayes.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names) / matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10: Which models performed the best? Were there big differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC and Bayes did best. The numbers are generally similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11: Do you think it's more important to be sensitive to negativity or positivity? Do we want more positive things incorrectly marked as negative, or more negative things marked as positive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It depends! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12: They all had very different training times. Which ones offer the best combination of performance and not making you wait around for an hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC and Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13: If you have a decent algorithm that trains more quickly, that could that mean about feature selection or the size of your training set? Why did we use `max_features=` and `df.sample`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used max_features and df.sample to cut down on the time needed to run the samples. If we have a model\n",
    "# that works quickly, we can make the training set or feature selection larger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14: How do you feel about sentiment analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15: How do you feel about [this piece from the UpShot](https://www.nytimes.com/interactive/2017/02/28/upshot/trump-sounds-different-tone-in-first-address-to-congress.html) that uses [the Emotional Lexicon](http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 16: What would you feel comfortable using our sentiment classifier for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something more standardised/less nuanced -- maybe advertisements? Or product/movie reviews since we have\n",
    "# good models for these specific topics\n",
    "\n",
    "# I'd feel comfortable using it in an exploratory way. Get a lede, and report it out to see if it's true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
